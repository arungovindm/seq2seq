{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_wAttention.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arungovindm/seq2seq/blob/master/seq2seq_wAttention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "fiS6KTQl7ya8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Pre-processing parameters\n",
        "</br>seq length threshold</br>count threshold\n",
        "\n",
        "\n",
        "##Hyperparamters of the model\n",
        "</br>batch_size\n",
        "</br>embedding dimensions\n",
        "</br>LSTM units"
      ]
    },
    {
      "metadata": {
        "id": "p7Gk35Vv8hYC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Install and import dependencies"
      ]
    },
    {
      "metadata": {
        "id": "U3JDmVKHtYTX",
        "colab_type": "code",
        "outputId": "e02fe1a3-2801-437d-b6b6-f48fb1345190",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl \n",
        "!pip3 install torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==0.4.1 from http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n",
            "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl (483.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 483.0MB 33.3MB/s \n",
            "\u001b[31mfastai 1.0.50.post1 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mfastai 1.0.50.post1 has requirement torch>=1.0.0, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 1.0.1.post2\n",
            "    Uninstalling torch-1.0.1.post2:\n",
            "      Successfully uninstalled torch-1.0.1.post2\n",
            "Successfully installed torch-0.4.1\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.2.post3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f5qyxGzFtiOu",
        "colab_type": "code",
        "outputId": "e0a228a1-bee7-4070-fcb7-21438821a7fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import re\n",
        "import time\n",
        "import keras\n",
        "import string\n",
        "\n",
        "print(torch.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ISvulUdX8oPh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Load data"
      ]
    },
    {
      "metadata": {
        "id": "tUhh6TpDt3RT",
        "colab_type": "code",
        "outputId": "43a27fa6-0171-4c18-ef24-704a83c39441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ElSfuFU_uMnI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "en = open('/content/drive/My Drive/nmt/europarl-v7.de-en.en', encoding='UTF-8').read().strip().split('\\n')\n",
        "de = open('/content/drive/My Drive/nmt/europarl-v7.de-en.de', encoding='UTF-8').read().strip().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_xmbMSXI80qp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Building vocabulary"
      ]
    },
    {
      "metadata": {
        "id": "UgpRhZ0p8uCz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Set vocabulary Hyper-parameters"
      ]
    },
    {
      "metadata": {
        "id": "0M707824vUTK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sent_threshold=15\n",
        "count_threshold=15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2uojILuXwBDV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "de_m=[]\n",
        "en_m=[]\n",
        "for i in range(len(de)):\n",
        "  if len(de[i].split(' '))< sent_threshold+1 and len(en[i].split(' '))< sent_threshold+1:\n",
        "    en_m.append(en[i])\n",
        "    de_m.append(de[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xbv-nMpl8-qa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Tokenize"
      ]
    },
    {
      "metadata": {
        "id": "3QD1Ca1CwDtN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "t= Tokenizer(num_words=30000,lower=True,oov_token='<UNK>')\n",
        "t.fit_on_texts(en_m)\n",
        "\n",
        "t_d= Tokenizer(num_words=30000,lower=True,oov_token='<UNK>')\n",
        "t_d.fit_on_texts(de_m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jStBjTOhxGWN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t2=Tokenizer()\n",
        "t_d2=Tokenizer()\n",
        "t2.word_counts['<UNK>']=0\n",
        "for word,counts in t.word_counts.items():\n",
        "  if counts < count_threshold:\n",
        "    t2.word_index[word]=3\n",
        "    t2.word_counts['<UNK>']=t2.word_counts['<UNK>']+counts\n",
        "    \n",
        "  else:\n",
        "    t2.word_index[word]=t.word_index[word]+2\n",
        "    t2.word_counts[word]=t.word_counts[word]\n",
        "    \n",
        "t_d2.word_counts['<UNK>']=0\n",
        "for word,counts in t_d.word_counts.items():\n",
        "  if counts < count_threshold:\n",
        "    t_d2.word_index[word]=3\n",
        "    t_d2.word_counts['<UNK>']=t_d2.word_counts['<UNK>']+counts\n",
        "    \n",
        "  else:\n",
        "    t_d2.word_index[word]=t_d.word_index[word]+2\n",
        "    t_d2.word_counts[word]=t_d.word_counts[word]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PrgsS5aSx0wD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t2.word_index['<pad>']=0\n",
        "t2.word_index['<start>']=1\n",
        "t2.word_index['<end>']=2\n",
        "\n",
        "t_d2.word_index['<pad>']=0\n",
        "t_d2.word_index['<start>']=1\n",
        "t_d2.word_index['<end>']=2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o9e_mfdW9Zpz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Functions to get padded, indexed sequence"
      ]
    },
    {
      "metadata": {
        "id": "HKEInOdSxNpt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def index_batch(t,batch,flag): #batch will be a list of size [batchsize] with each item being a sentence\n",
        "  for i in range(len(batch)):\n",
        "    batch[i]=batch[i].split(' ')\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    stripped = [w.translate(table).lower() for w in batch[i]]\n",
        "    for j in range(len(batch[i])):\n",
        "      if stripped[j]  not in t.word_index:\n",
        "        batch[i][j]=3\n",
        "      else:\n",
        "        batch[i][j]=t.word_index[stripped[j].lower()]\n",
        "    if flag=='decoder':\n",
        "      start_token=np.array(1)\n",
        "      stop_token=np.array(2)\n",
        "      batch[i]=np.hstack([start_token,batch[i],stop_token])\n",
        "\n",
        "  return batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C2A2BMX87OVd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_batch(text,t,flag='encoder'):  #returns the padded indexed np.array of given batch number\n",
        "  batch=index_batch(t,text,flag)\n",
        "  batch=keras.preprocessing.sequence.pad_sequences(batch,dtype=int,padding='post',truncating='post',value=0)\n",
        "  return batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1ZXa0NQQze1o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Parameters"
      ]
    },
    {
      "metadata": {
        "id": "v5OjoZ50xv8l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "global batch_size, data_size,embedding_dims,units\n",
        "learning_rate = 0.001\n",
        "BUFFER_SIZE = len(en_m)\n",
        "batch_size=32\n",
        "N_BATCH = BUFFER_SIZE//batch_size\n",
        "units=128\n",
        "data_size = len(en_m)\n",
        "en_vocab_size=len(t2.word_counts)+3 #same as below\n",
        "de_vocab_size=len(t_d2.word_counts)+3 #adding start stop and pad tokens\n",
        "embedding_dims=150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2m2dzxjF96vx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Create dataset"
      ]
    },
    {
      "metadata": {
        "id": "PI9Z_cXFzPIm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ucbbW56d5fJe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        # TODO: convert this into torch code is possible\n",
        "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        x_len = self.length[index]\n",
        "        return x,y,x_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KOztHMTW53m6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_tensor = get_batch(en_m,t2,'decoder')\n",
        "target_tensor = get_batch(de_m,t_d2,'decoder')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y_yIQvCY5i8i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset = MyData(input_tensor, target_tensor)\n",
        "dataset = DataLoader(train_dataset, batch_size, \n",
        "                      drop_last=True,\n",
        "                      shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zIZJSX7g-Bj5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Encoder class"
      ]
    },
    {
      "metadata": {
        "id": "eTqDKfiI6RM1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.gru = nn.LSTM(self.embedding_dim, self.enc_units)\n",
        "        \n",
        "    def forward(self, x, lens, device):\n",
        "        x=x.transpose(0,1)\n",
        "        x = self.embedding(x) \n",
        "        x = x.permute(1,0,2)\n",
        "        x = pack_padded_sequence(x, lens) # unpad\n",
        "    \n",
        "        self.hidden_state = self.initialize_hidden_state(device)\n",
        "        self.cell_state = self.initialize_hidden_state(device)\n",
        "        \n",
        "        output, (self.hidden_state,self.cell_state) = self.gru(x, (self.hidden_state,self.cell_state)) # gru returns hidden state of all timesteps as well as hidden state at last timestep\n",
        "        \n",
        "        # pad the sequence to the max length in the batch\n",
        "        output, _ = pad_packed_sequence(output)\n",
        "        \n",
        "        return output, (self.hidden_state, self.cell_state)\n",
        "\n",
        "    def initialize_hidden_state(self, device):\n",
        "        return torch.zeros((1, self.batch_sz, self.enc_units)).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3gRe7-TA6Szv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### sort batch function to be able to use with pad_packed_sequence\n",
        "def sort_batch(X, y, lengths):\n",
        "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
        "    X = X[indx]\n",
        "    y = y[indx]\n",
        "    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QDrGIqsM-Mnz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Decoder class"
      ]
    },
    {
      "metadata": {
        "id": "nLTGgSRKJUcS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, enc_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.enc_units = enc_units\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.lstm = nn.LSTM(self.embedding_dim + self.enc_units, \n",
        "                          self.dec_units,\n",
        "                          batch_first=True)\n",
        "        self.fc = nn.Linear(self.enc_units, self.vocab_size)\n",
        "        \n",
        "        self.W1 = nn.Linear(self.enc_units, self.dec_units)\n",
        "        self.W2 = nn.Linear(self.enc_units, self.dec_units)\n",
        "        self.V = nn.Linear(self.enc_units, 1)\n",
        "    \n",
        "    def forward(self, x, hidden,cell, enc_output):\n",
        "        enc_output = enc_output.permute(1,0,2)\n",
        "        \n",
        "        hidden_with_time_axis = hidden.permute(1, 0, 2)\n",
        "        \n",
        "        score = torch.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis))\n",
        "        \n",
        "        attention_weights = torch.softmax(self.V(score), dim=1)\n",
        "        \n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector = attention_weights * enc_output\n",
        "        context_vector = torch.sum(context_vector, dim=1)\n",
        "        \n",
        "        x = self.embedding(x)\n",
        "        \n",
        "        x = torch.cat((context_vector.unsqueeze(1), x), -1)\n",
        "        \n",
        "        # passing the concatenated vector to the LSTM\n",
        "        # output: (batch_size, 1, hidden_size)\n",
        "        output, (hstate,cstate) = self.lstm(x)\n",
        "        \n",
        "        \n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output =  output.view(-1, output.size(2))\n",
        "        \n",
        "        # output shape == (batch_size * 1, vocab)\n",
        "        x = self.fc(output)\n",
        "        \n",
        "        return x, (hstate,cstate) ,attention_weights\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return torch.zeros((2,1, self.batch_sz, self.dec_units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vIcsXn0E4glo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#vanilla seq2seq\n",
        "class vanillaDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, enc_units, batch_sz):\n",
        "        super(vanillaDecoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.enc_units = enc_units\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.gru = nn.LSTM(self.embedding_dim, \n",
        "                          self.dec_units,\n",
        "                          batch_first=True)\n",
        "        self.fc = nn.Linear(self.enc_units, self.vocab_size)\n",
        "        \n",
        "    \n",
        "    def forward(self, x, hidden,cell, enc_output):\n",
        "        enc_output = enc_output.permute(1,0,2)\n",
        "        \n",
        "        hidden_with_time_axis = hidden.permute(1, 0, 2)\n",
        "        \n",
        "        x = self.embedding(x)\n",
        "        \n",
        "        output, (hstate,cstate) = self.gru(x)\n",
        "        \n",
        "        \n",
        "        output =  output.view(-1, output.size(2))\n",
        "        \n",
        "        # output shape == (batch_size * 1, vocab)\n",
        "        x = self.fc(output)\n",
        "        \n",
        "        return x, (hstate,cstate)     \n",
        "    def initialize_hidden_state(self):\n",
        "        return torch.zeros((2,1, self.batch_sz, self.dec_units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N820pjJyMcnS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#encoder_outputs shape ([17, 64, 128])\n",
        "#decoder input ([64, 1])\n",
        "class Multiplicative_decoder(nn.Module):\n",
        "  def __init__(self, vocab_size,embedding_dim, enc_units, dec_units, batch_sz):\n",
        "    super(Multiplicative_decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.enc_units = enc_units\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "    self.lstm=nn.LSTM(self.embedding_dim,self.dec_units,batch_first=True)\n",
        "    self.pred_layer=nn.Linear(self.enc_units + self.dec_units, self.vocab_size)\n",
        "    \n",
        "    \n",
        "    #attention part\n",
        "    k=self.enc_units**(-0.5)\n",
        "    a=torch.FloatTensor(self.enc_units,self.dec_units).uniform_(-1,1)\n",
        "    self.W = nn.Parameter(a)\n",
        "    \n",
        "    \n",
        "  def forward(self, x, hstate, cstate, enc_output):\n",
        "    k=self.enc_units**(-0.5)\n",
        "\n",
        "    x = self.embedding(x)\n",
        "    s, (hstate, cstate) = self.lstm(x)\n",
        "    \n",
        "    #enc_outputs are seq x batch_size x  enc_units\n",
        "    sequence_length, batch_size, self.enc_units = enc_output.shape\n",
        "    enc_output=enc_output.permute(1,0,2)\n",
        "    \n",
        "    attention = torch.matmul(torch.matmul(enc_output,self.W) ,hstate.permute(1,2,0))\n",
        "    attention_weights = torch.softmax(attention,dim=1)\n",
        "    #print(attention_weights)\n",
        "\n",
        "    enc_output=enc_output.permute(1,0,2)\n",
        "    \n",
        "    attention_weights=attention_weights.permute(1,0,2)\n",
        "\n",
        "    context_vector = attention_weights * enc_output\n",
        "    context_vector = torch.sum(context_vector, dim=0)\n",
        "    pred_vec = torch.cat((context_vector.unsqueeze(2),hstate.permute(1,2,0)),1).squeeze()\n",
        "    \n",
        "    output = self.pred_layer(pred_vec)\n",
        "    \n",
        "    return output, (hstate,cstate),attention_weights\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n0HSoLbn-UyZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Define loss function"
      ]
    },
    {
      "metadata": {
        "id": "XkU1cJScLcRL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    \"\"\" Only consider non-zero inputs in the loss; mask needed \"\"\"\n",
        "    loss_ = criterion(pred, real) \n",
        "    return torch.mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KSytHedxWMZG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device = torch.device(\"cpu\")\n",
        "\n",
        "encoder = Encoder(en_vocab_size, embedding_dims, units, batch_size)\n",
        "decoder = Multiplicative_decoder(de_vocab_size, embedding_dims, units, units, batch_size)\n",
        "\n",
        "encoder.to(device)\n",
        "decoder.to(device)\n",
        "\n",
        "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), \n",
        "                       lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hePv6fHE-Y-8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Train"
      ]
    },
    {
      "metadata": {
        "id": "pwqtiGvqWZ-o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    \n",
        "    total_loss = 0\n",
        "    \n",
        "    for (batch, (inp, targ, inp_len)) in enumerate(dataset):\n",
        "        loss = 0\n",
        "        \n",
        "        xs, ys, lens = sort_batch(inp, targ, inp_len)\n",
        "        \n",
        "#         print(\"Output: \", targ.shape)\n",
        "        enc_output, (enc_hidden,enc_cell) = encoder(xs.to(device), lens, device)\n",
        "        dec_hidden = enc_hidden\n",
        "        dec_cell = enc_cell\n",
        "        #print(enc_output.size())\n",
        "        \n",
        "        \n",
        "        # use teacher forcing - feeding the target as the next input (via dec_input)\n",
        "        dec_input = torch.tensor([[t_d2.word_index['<start>']]] * batch_size)\n",
        "        #print(dec_input.size())\n",
        "        # run code below for every timestep in the ys batch\n",
        "        for t in range(1, ys.size(1)):\n",
        "            predictions, (dec_hidden,dec_cell),att_weights = decoder(dec_input.to(device),\n",
        "                                                            dec_hidden.to(device),\n",
        "                                                            dec_cell.to(device),\n",
        "                                                            enc_output.to(device))\n",
        "            #print('prediction shape',predictions.size())\n",
        "            loss += loss_function(ys[:, t].to(device), predictions.to(device))\n",
        "            #loss += loss_\n",
        "            dec_input = ys[:, t].unsqueeze(1)\n",
        "            \n",
        "        \n",
        "        batch_loss = (loss / int(ys.size(1)))\n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        loss.backward()\n",
        "\n",
        "        ### UPDATE MODEL PARAMETERS\n",
        "        optimizer.step()\n",
        "        \n",
        "#         if batch % 100 == 0:\n",
        "#           print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "#                                                            batch,\n",
        "#                                                            batch_loss.detach().item()))\n",
        "        \n",
        "        \n",
        "    ### TODO: Save checkpoint for model\n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                        total_loss / N_BATCH))\n",
        "    if epoch ==4:\n",
        "      torch.save(encoder.state_dict(),'/content/drive/My Drive/nmt/mult/enc_64')\n",
        "      torch.save(decoder.state_dict(),'/content/drive/My Drive/nmt/mult/dec_64')\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wq1t2kbs5kNz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Saving the model"
      ]
    },
    {
      "metadata": {
        "id": "I5baz9IK6tJT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Saving learned parameters"
      ]
    },
    {
      "metadata": {
        "id": "bCfUkSsdwu7Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.save(encoder.state_dict(),'/content/drive/My Drive/nmt/hstate_50_dim/enc_mult')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_7jF1hr0wWcD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.save(decoder.state_dict(),'/content/drive/My Drive/nmt/hstate_50_dim/dec_mult')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BxkrTRvT6mEV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Loading learned parameters"
      ]
    },
    {
      "metadata": {
        "id": "KwkvsH3KSdhO",
        "colab_type": "code",
        "outputId": "d8798971-dc54-4399-95ea-66091e480d29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "del device\n",
        "device=torch.device(\"cpu\")\n",
        "add_dec = Decoder(de_vocab_size, embedding_dims, units, units, 1)\n",
        "add_dec.load_state_dict(torch.load('/content/drive/My Drive/nmt/additive_embedding_150_bsize64_s15_fr15/dec'))\n",
        "add_enc = Encoder(en_vocab_size, embedding_dims, units, 1)\n",
        "add_enc.load_state_dict(torch.load('/content/drive/My Drive/nmt/additive_embedding_150_bsize64_s15_fr15/enc'))\n",
        "add_dec.eval()\n",
        "add_enc.eval()"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoder(\n",
              "  (embedding): Embedding(9714, 150)\n",
              "  (gru): LSTM(150, 128)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "metadata": {
        "id": "WoFABAgNXq0J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "index_dict=dict()\n",
        "for word, index in t_d2.word_index.items():\n",
        "  index_dict[index]=word\n",
        "  \n",
        "en_index_dict=dict()\n",
        "for word, index in t2.word_index.items():\n",
        "  en_index_dict[index]=word\n",
        "  \n",
        "  \n",
        "index_dict[3]='<UNK>'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vE-zZjdilN1N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Test set"
      ]
    },
    {
      "metadata": {
        "id": "UdDU3m77Qsmx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_en = open('/content/drive/My Drive/nmt/test_set/newssyscomb2009.en', encoding='UTF-8').read().strip().split('\\n')\n",
        "test_de = open('/content/drive/My Drive/nmt/test_set/newssyscomb2009.de', encoding='UTF-8').read().strip().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QIso-mtZGT_V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tokenize(batch):\n",
        "  for i in range(len(batch)):\n",
        "      batch[i]=batch[i].split(' ')\n",
        "      table = str.maketrans('', '', string.punctuation)\n",
        "      batch[i] = [w.translate(table).lower() for w in batch[i]]\n",
        "  return batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WfALDLrjNaab",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## sort batch function to be able to use with pad_packed_sequence\n",
        "def sort_testbatch(X, lengths):\n",
        "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
        "    X = X[indx]\n",
        "    return X.transpose(0,1), lengths # transpose (batch x seq) to (seq x batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VDp_7UkOMbs7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "global attn\n",
        "def translate(add_enc,add_dec,test,length):\n",
        "  sent1=\"\"\n",
        "  # sent2=\"\"\n",
        "  output, (hstate,cstate)=add_enc(test.to(device),length.to(device),device)\n",
        "  dec_input = torch.tensor([[t_d2.word_index['<start>']]] * 1)\n",
        "  dec_hidden=hstate\n",
        "  dec_cell=cstate\n",
        "  word1=\"\"\n",
        "  # word2=\"\"\n",
        "\n",
        "  predictions, (dec_hidden,dec_cell),attn = add_dec(dec_input.to(device),\n",
        "                                                                dec_hidden.to(device),\n",
        "                                                                dec_cell.to(device),\n",
        "                                                                output.to(device))\n",
        "  print(attn)\n",
        "  #predictions=predictions.unsqueeze(0)\n",
        "  t=0\n",
        "  while word1 !='<end>' and t<17:\n",
        "    _, indices = predictions.max(1)\n",
        "    \n",
        "#     print(indices.shape)\n",
        "    word1= index_dict[int(indices[0])]\n",
        "  #   word2= index_dict[int(indices[1])]\n",
        "    sent1 = sent1+\" \"+ word1\n",
        "  #   sent2 = sent2+\" \"+ word2\n",
        "    dec_input = torch.tensor([[int(indices[0])]])\n",
        "    predictions, (dec_hidden,dec_cell),attn = add_dec(dec_input.to(device),\n",
        "                                                                dec_hidden.to(device),\n",
        "                                                                dec_cell.to(device),\n",
        "                                                                output.to(device))\n",
        "    #predictions=predictions.unsqueeze(0)\n",
        "    t=t+1\n",
        "  return sent1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SnpJGtrzk3Yp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "de_t=[]\n",
        "en_t=[]\n",
        "tester_bitch=[]\n",
        "tester_bitch2=[]\n",
        "for i in range(len(test_de)):\n",
        "  if len(test_de[i].split(' '))< sent_threshold+1 and len(test_en[i].split(' '))< sent_threshold+1:\n",
        "    tester_bitch.append(test_en[i])\n",
        "    tester_bitch2.append(test_de[i])\n",
        "    #print(test_en[i])\n",
        "    en_t.append(test_en[i])\n",
        "    de_t.append(test_de[i])\n",
        "tester_bitch=tokenize(tester_bitch)\n",
        "long = []\n",
        "for i in tester_bitch:\n",
        "  long.append(len(i))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NJZ0Okzcivpa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##BLEU Calculation"
      ]
    },
    {
      "metadata": {
        "id": "7XY_Z0ulw4DP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "long=torch.tensor(long)\n",
        "long, indx = long.sort(dim=0, descending=True)\n",
        "for i in range(len(long)):\n",
        "  tester_bitch[i] = tester_bitch[indx[i]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5XqargKylHmD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_input_tensor = get_batch(en_t,t2,'decoder')\n",
        "test_target_tensor = get_batch(de_t,t_d2,'decoder')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4vsF9KFAlie2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "length = [ np.sum(1 - np.equal(x, 0)) for x in test_input_tensor]\n",
        "length=torch.tensor(length,dtype=torch.int32)\n",
        "test_ins,lengths = sort_testbatch(test_input_tensor,length)\n",
        "test_outs,leng = sort_testbatch(test_target_tensor,length)\n",
        "test_ins=torch.tensor(test_ins)\n",
        "sentence=[]\n",
        "for i in range(len(tester_bitch)):\n",
        "  test=test_ins[i,:].unsqueeze(1)\n",
        "  l=torch.tensor([lengths[i].tolist()])\n",
        "  #print(l)\n",
        "  sentence.append(translate(add_enc,add_dec,test,l))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wDCPiq7LmhPa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "source=[]\n",
        "test_outs=test_outs.transpose(0,1)\n",
        "for i in range(len(test_outs)):\n",
        "  sent=\"\"\n",
        "  for j in range(len(test_outs[i])):\n",
        "    \n",
        "    if int(test_outs[i][j]) >2: \n",
        "      sent=sent+index_dict[int(test_outs[i][j])]+' '\n",
        "    \n",
        "  source.append(sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OsGzHP0nq2ct",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(source)):\n",
        "  source[i]=source[i].split(' ')\n",
        "  sentence[i]=sentence[i].split(' ')\n",
        "  source[i].append('<end>')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "InWpF5zL9CZ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(source)):\n",
        "  source[i]= list(filter( lambda x: x not in ['<end>','','<start>','<pad>'],source[i]))\n",
        "  sentence[i]= list(filter( lambda x: x not in ['<end>','','<start>','<pad>'],sentence[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YF8ByD1H5Mei",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ref = []\n",
        "for sent in source:\n",
        "  ref.append([sent])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RLyRDb8M5Qgq",
        "colab_type": "code",
        "outputId": "d3abfff5-f6cb-493c-d44d-393f806c86c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "corpus_bleu(ref,sentence)"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2084896067711646"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "metadata": {
        "id": "-kc3lf03APDu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "seq2seq 1.180844816106659</br>\n",
        "Additive 128 enc units---> 8.525364965063201</br>\n",
        "Additive 64 enc units ----> 7.966707348359717</br>\n",
        "Multiplicative 3.8322325669944445  not --->0.012138092763158777</br>\n",
        "Scaled dot 3.797474380138463 not ---->0.031393753345098786</br>\n",
        "\n",
        "  "
      ]
    }
  ]
}